{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9cd2d3",
   "metadata": {
    "id": "6b9cd2d3"
   },
   "source": [
    "Curso de Big Data\n",
    "==============================\n",
    "\n",
    "Trabajo práctico 4\n",
    "------------------------------\n",
    "\n",
    "### Grupo: Armas Braithwaite, Fernández, Menta, Vargas Ochuza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63417974",
   "metadata": {
    "id": "63417974"
   },
   "source": [
    "## Parte 1: Análisis de la base de hogares y cálculo de pobreza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a591f3",
   "metadata": {
    "id": "22a591f3"
   },
   "outputs": [],
   "source": [
    "# Importamos los módulos necesarios para trabajar con la base de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44859a7",
   "metadata": {},
   "source": [
    "### Inciso 1\n",
    "Descarguen la base de microdatos de la EPH correspondiente al primer trimestre de 2023 (la base de hogares se llama usu hogar T123.xls). Importen los datos de la encuesta de hogar y, al igual que en los trabajos anteriores, conserven solo las observaciones que corresponden a los aglomerados de Ciudad Autónoma de Buenos Aires o del Gran Buenos Aires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66689972",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "error",
     "timestamp": 1699898470258,
     "user": {
      "displayName": "Paula Isabel Armas Braithwaite",
      "userId": "03414319077384874698"
     },
     "user_tz": 180
    },
    "id": "66689972",
    "outputId": "9b31613d-15b8-49d1-dd69-3ff7c34f9219"
   },
   "outputs": [],
   "source": [
    "# Cargamos las bases\n",
    "microdata_hogar = pd.read_excel(\"usu_hogar_T123.xlsx\")\n",
    "microdata_indv = pd.read_excel(\"usu_individual_T123.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e16d60",
   "metadata": {
    "id": "e6e16d60"
   },
   "outputs": [],
   "source": [
    "# Del diccionario de variables sabemos que tenemos que quedarnos solamente con los valores 32 y 33\n",
    "# que son los correspondientes a Ciudad Autónoma de Buenos Aires o Gran Buenos Aires.\n",
    "\n",
    "# Filtramos el dataframe y lo renombramos\n",
    "microdata_indv_filtered = microdata_indv[(microdata_indv['AGLOMERADO'] == 32) | (microdata_indv['AGLOMERADO'] == 33)]\n",
    "len(microdata_indv_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5885022",
   "metadata": {
    "id": "d5885022"
   },
   "outputs": [],
   "source": [
    "# Filtramos el dataframe y lo renombramos\n",
    "microdata_hogar_filtered = microdata_hogar[(microdata_hogar['AGLOMERADO'] == 32) | (microdata_hogar['AGLOMERADO'] == 33)]\n",
    "len(microdata_hogar_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef1b850",
   "metadata": {
    "id": "bef1b850"
   },
   "source": [
    "### Inciso 2\n",
    "Unan la tabla de la encuesta individual con la de la encuesta de hogar. Asegúrense de estar usando las variables CODUSU y NRO HOGAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3869d7",
   "metadata": {
    "id": "1e3869d7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Realizamos un inner join de las bases para quedarnos solo con las filas cuyo identificador de hogar se encuentre en ambas bases\n",
    "# Importante remarcar que hacemos el merge por vivienda y hogar! ya que pueden haber 2 viviendas en un mismo hogar.\n",
    "\n",
    "merged_microdata = microdata_indv_filtered.merge(microdata_hogar_filtered, on=['CODUSU', \"NRO_HOGAR\"], how='inner')\n",
    "\n",
    "# Renombrar las columnas con sufijo \"_x\" a \"_indv\"\n",
    "merged_microdata.rename(columns=lambda x: x.replace(\"_x\", \"_indv\"), inplace=True)\n",
    "\n",
    "# Renombrar las columnas con sufijo \"_y\" a \"_hogar\"\n",
    "merged_microdata.rename(columns=lambda x: x.replace(\"_y\", \"_hogar\"), inplace=True)\n",
    "\n",
    "# Esto ultimo no es particularmente necesario pues muchos de los valores son duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca3511",
   "metadata": {
    "id": "1cca3511"
   },
   "outputs": [],
   "source": [
    "# Chequeamos la dimension\n",
    "len(merged_microdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0083a",
   "metadata": {
    "id": "9dd0083a"
   },
   "outputs": [],
   "source": [
    "# Chequeamos la dimension\n",
    "len(merged_microdata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f07e0c",
   "metadata": {},
   "source": [
    "### Inciso 3\n",
    "Limpien la base de datos tomando criterios que hagan sentido, tanto para el tratamiento de valores faltantes, de outliers, como así tambiín decidan qué variables categóricas y strings usarán y transfórmenlas de forma que haga sentido para los ejercicios siguientes. Justifiquen sus decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4497d",
   "metadata": {
    "id": "78c4497d"
   },
   "outputs": [],
   "source": [
    "# Identificar variables con NaN y contar cuántos NaN\n",
    "# Utilizamos funciones de Pandas para identificar y limpiar NaN.\n",
    "\n",
    "variables_con_nan = merged_microdata.columns[merged_microdata.isna().any()].tolist()\n",
    "conteo_de_nans = merged_microdata[variables_con_nan].isna().sum()\n",
    "\n",
    "# Imprimir las variables con NaN y la cantidad de NaN en cada una\n",
    "for variable in variables_con_nan:\n",
    "    print(f'Variable: {variable}, Cantidad de NaN: {conteo_de_nans[variable]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8ff95",
   "metadata": {
    "id": "95b8ff95"
   },
   "outputs": [],
   "source": [
    "# Establecer el umbral para determinar qué columnas eliminar\n",
    "# El umbral aquí es el número mínimo de valores no-NaN que debe tener la columna para no ser eliminada\n",
    "total_filas = len(merged_microdata)\n",
    "umbral = total_filas - 3500\n",
    "\n",
    "# Eliminar columnas con más de 3500 valores NaN\n",
    "merged_microdata = merged_microdata.dropna(thresh=umbral, axis=1)\n",
    "\n",
    "print(len(merged_microdata))  # Esto imprime el número de filas.\n",
    "print(len(merged_microdata.columns))  # Esto imprime el número de columnas restantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf4e2d",
   "metadata": {
    "id": "afdf4e2d"
   },
   "outputs": [],
   "source": [
    "# Identificar variables con NaN y contar cuántos NaN\n",
    "# Utilizamos funciones de Pandas para identificar y limpiar NaN.\n",
    "\n",
    "variables_con_nan = merged_microdata.columns[merged_microdata.isna().any()].tolist()\n",
    "conteo_de_nans = merged_microdata[variables_con_nan].isna().sum()\n",
    "\n",
    "# Imprimir las variables con NaN y la cantidad de NaN en cada una\n",
    "for variable in variables_con_nan:\n",
    "    print(f'Variable: {variable}, Cantidad de NaN: {conteo_de_nans[variable]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e89f55",
   "metadata": {
    "id": "f1e89f55"
   },
   "outputs": [],
   "source": [
    "# Eliminar las observaciones con NaN\n",
    "merged_microdata.dropna(subset=['CH08'], inplace=True)\n",
    "merged_microdata.dropna(subset=['P47T'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc5c9f",
   "metadata": {
    "id": "f0dc5c9f"
   },
   "outputs": [],
   "source": [
    "print(len(merged_microdata))\n",
    "print(len(merged_microdata.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847e44e",
   "metadata": {
    "id": "5847e44e"
   },
   "outputs": [],
   "source": [
    "# Definimos las variables que deseamos filtrar\n",
    "variables = ['ITF_hogar', 'ITF_indv', 'IPCF_hogar', 'IPCF_indv', 'P21', 'P47T']\n",
    "\n",
    "# Definir el umbral del percentil (en este caso, 97%)\n",
    "percentile_threshold = 0.97\n",
    "\n",
    "# Iterar sobre las variables y aplicar el filtrado utlizando Pandas.\n",
    "for variable in variables:\n",
    "    # Calcular el percentil umbral\n",
    "    percentile_value = merged_microdata[variable].quantile(percentile_threshold)\n",
    "\n",
    "    # Filtrar el DataFrame para mantener solo los valores por debajo del percentil\n",
    "    merged_microdata = merged_microdata[merged_microdata[variable] <= percentile_value]\n",
    "\n",
    "len(merged_microdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7c6d9",
   "metadata": {
    "id": "6db7c6d9"
   },
   "outputs": [],
   "source": [
    "# Eliminar aquellas columnas que contienen string y no aportan al análisis, y aquellas variables que tienen\n",
    "# los mismos valores para todas las observaciones debido a que pueden generar multicolinealidad y no\n",
    "# aportan variabilidad\n",
    "merged_microdata = merged_microdata.drop(columns=['ANO4_indv','TRIMESTRE_indv','REGION_indv','ANO4_hogar','TRIMESTRE_hogar','REGION_hogar', 'CH05', 'MAS_500_indv', 'MAS_500_hogar'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c212d",
   "metadata": {
    "id": "2f1c212d"
   },
   "outputs": [],
   "source": [
    "# Transformamos las variables categóricas enteras en dummies\n",
    "\n",
    "# Lista de columnas categóricas para convertir a dummies\n",
    "columns_to_dummies = ['NIVEL_ED', 'CH07', 'CH08', 'CH09', 'CH12', 'CH15', 'CH16', 'ESTADO', 'CAT_OCUP', 'CAT_INAC']\n",
    "\n",
    "# Crear dummies y concatenar con el DataFrame original excluyendo las columnas originales\n",
    "merged_microdata = pd.get_dummies(merged_microdata, columns=columns_to_dummies)\n",
    "\n",
    "# merged_microdata_with_dummies ahora tiene las variables originales más las dummies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04dbce",
   "metadata": {
    "id": "4f04dbce"
   },
   "outputs": [],
   "source": [
    "len(merged_microdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc4454",
   "metadata": {
    "id": "b6cc4454"
   },
   "outputs": [],
   "source": [
    "# Limpiamos algunas variables con valores especificos utlizando Pandas\n",
    "\n",
    "merged_microdata = merged_microdata[merged_microdata['IV2'] != 99]\n",
    "merged_microdata = merged_microdata[merged_microdata['II1'] != 99]\n",
    "merged_microdata = merged_microdata[merged_microdata['II9'] > 0]\n",
    "merged_microdata = merged_microdata[merged_microdata['ITF_hogar'] >= 0]\n",
    "merged_microdata = merged_microdata[merged_microdata['ITF_indv'] >= 0]\n",
    "merged_microdata = merged_microdata[merged_microdata['IPCF_hogar'] >= 0]\n",
    "merged_microdata = merged_microdata[merged_microdata['IPCF_indv'] >= 0]\n",
    "\n",
    "\n",
    "len(merged_microdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3674be",
   "metadata": {},
   "source": [
    "### Inciso 4\n",
    "Construyan variables (mínimo 2) que no estén en la base pero que sean relevantes para predecir individuos bajo la línea de pobreza (por ejemplo, la proporción de niños en el hogar, si el cónyuge trabaja)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prop de ninos en el hogar\n",
    "\n",
    "# Agregar la variable prop_ninos\n",
    "merged_microdata['prop_ninos'] = merged_microdata['IX_MEN10'] / merged_microdata['IX_TOT']\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "merged_microdata['prop_ninos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24810f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jefe con primaria incompleta\n",
    "merged_microdata['Jefe_primaria_incompleta'] = merged_microdata.apply(lambda row: 1 if row['CH03'] == 1 and row['NIVEL_ED_1'] == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar cuántos valores son iguales a 1 en la nueva variable\n",
    "cantidad_uno = merged_microdata['Jefe_primaria_incompleta'].sum()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"La cantidad de 1 en la variable Jefe_primaria_incompleta es: {cantidad_uno}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jefe con primaria incompleta\n",
    "merged_microdata['Jefe_Secundaria_incompleta'] = merged_microdata.apply(lambda row: 1 if row['CH03'] == 1 and row['NIVEL_ED_2'] == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af106de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar cuántos valores son iguales a 1 en la nueva variable\n",
    "cantidad_uno = merged_microdata['Jefe_Secundaria_incompleta'].sum()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"La cantidad de 1 en la variable Jefe_Secundaria_incompleta es: {cantidad_uno}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bfb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la cantidad total de personas en cada hogar\n",
    "total_personas_por_hogar = merged_microdata.groupby('NRO_HOGAR')['NIVEL_ED_4'].transform('sum')\n",
    "\n",
    "# Calcular la proporción de personas con secundario incompleto en cada hogar\n",
    "merged_microdata['Prop_Univ_Incompleto'] = total_personas_por_hogar / merged_microdata.groupby('NRO_HOGAR')['NRO_HOGAR'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Densidad del hogar\n",
    "\n",
    "# Agregar la variable densidad_hogar (miembros/ambientes)\n",
    "merged_microdata['prop_ninos'] = merged_microdata['IX_Tot_hogar'] / merged_microdata['IV2_hogar']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e5c4d",
   "metadata": {},
   "source": [
    "### Inciso 5\n",
    "Presenten un gráfico (que no sea de barras) para describir la interacción o correlación entre dos o más variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1359576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico: (IX_TOT;NIVEL_ED)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.scatter(x=merged_microdata['IX_TOT'], y=merged_microdata['ITF_hogar'], alpha=0.8)\n",
    "ax.set_xlabel('Miembros del Hogar')\n",
    "ax.set_ylabel('Ingreso total Familiar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrar el DataFrame por proporción de niños mayor o igual a 0.6\n",
    "prop_ninos_filtrada = merged_microdata[merged_microdata['prop_ninos'] >= 0.6]\n",
    "\n",
    "# Filtrar solo las filas con valores no nulos en las variables seleccionadas\n",
    "subset_data_corr = prop_ninos_filtrada[['prop_ninos', 'ITF_hogar']].dropna()\n",
    "\n",
    "# Configurar el estilo del gráfico\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Crear el gráfico de dispersión con línea de tendencia\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(x='prop_ninos', y='ITF_hogar', data=subset_data_corr)\n",
    "plt.title('Gráfico de Dispersión con Línea de Tendencia entre prop_ninos >= 0.6 e ITF_hogar')\n",
    "plt.xlabel('Proporción de Niños en el Hogar (>= 0.6)')\n",
    "plt.ylabel('Ingreso Total Familiar del Hogar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23117d2d",
   "metadata": {},
   "source": [
    "### Inciso 6\n",
    "Construyan la columna adulto_equiv y la columna ad_equiv_hogar y luego dividan la base en dos dataframes donde: uno conserve las personas que no reportaron ITF (dataframe llamado respondieron) y otro conserve a las personas que no reportaron ITF (llamado norespondieron). Además, agreguen a la base respondieron una columna llamada ingreso_necesario que sea el producto de la canasta\n",
    "básica por ad_equiv_hogar. Agreguen a la base respondieron una columna llamada pobre, que tome valor 1 si el ITF es menor al ingreso_necesario que necesita esa familia y 0 en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adc7fa",
   "metadata": {
    "id": "47adc7fa"
   },
   "outputs": [],
   "source": [
    "# Armamos una función para no tener que lidiar con el tedioso uso del archivo de Excel.\n",
    "\n",
    "# Esta función, asignar_valor, toma dos argumentos, edad y genero, y asigna un valor numérico basado en reglas condicionales\n",
    "# que dependen de estos dos argumentos. Las condiciones se prueban en orden y, cuando se encuentra una coincidencia, se\n",
    "# devuelve un valor específico. Si no se cumple ninguna condición, la función devuelve None.\n",
    "#Las condiciones están diseñadas para categorizar a las personas en grupos según su edad y género y asignarles un valor numérico basado en esas categorías.\n",
    "\n",
    "def asignar_valor(edad, genero):\n",
    "    if edad < 1:\n",
    "        if genero == 2:\n",
    "            return 0.35\n",
    "        elif genero == 1:\n",
    "            return 0.35\n",
    "    elif edad == 1:\n",
    "        if genero == 2:\n",
    "            return 0.37\n",
    "        elif genero == 1:\n",
    "            return 0.37\n",
    "    elif edad == 2:\n",
    "        if genero == 2:\n",
    "            return 0.46\n",
    "        elif genero == 1:\n",
    "            return 0.46\n",
    "    elif edad == 3:\n",
    "        if genero == 2:\n",
    "            return 0.51\n",
    "        elif genero == 1:\n",
    "            return 0.51\n",
    "    elif edad == 4:\n",
    "        if genero == 2:\n",
    "            return 0.55\n",
    "        elif genero == 1:\n",
    "            return 0.55\n",
    "    elif edad == 5:\n",
    "        if genero == 2:\n",
    "            return 0.60\n",
    "        elif genero == 1:\n",
    "            return 0.60\n",
    "    elif edad == 6:\n",
    "        if genero == 2:\n",
    "            return 0.64\n",
    "        elif genero == 1:\n",
    "            return 0.64\n",
    "    elif edad == 7:\n",
    "        if genero == 2:\n",
    "            return 0.66\n",
    "        elif genero == 1:\n",
    "            return 0.66\n",
    "    elif edad == 8:\n",
    "        if genero == 2:\n",
    "            return 0.68\n",
    "        elif genero == 1:\n",
    "            return 0.68\n",
    "    elif edad == 9:\n",
    "        if genero == 2:\n",
    "            return 0.69\n",
    "        elif genero == 1:\n",
    "            return 0.69\n",
    "    elif edad == 10:\n",
    "        if genero == 2:\n",
    "            return 0.70\n",
    "        elif genero == 1:\n",
    "            return 0.79\n",
    "    elif edad == 11:\n",
    "        if genero == 2:\n",
    "            return 0.72\n",
    "        elif genero == 1:\n",
    "            return 0.82\n",
    "    elif edad == 12:\n",
    "        if genero == 2:\n",
    "            return 0.74\n",
    "        elif genero == 1:\n",
    "            return 0.85\n",
    "    elif edad == 13:\n",
    "        if genero == 2:\n",
    "            return 0.76\n",
    "        elif genero == 1:\n",
    "            return 0.90\n",
    "    elif edad == 14:\n",
    "        if genero == 2:\n",
    "            return 0.76\n",
    "        elif genero == 1:\n",
    "            return 0.96\n",
    "    elif edad == 15:\n",
    "        if genero == 2:\n",
    "            return 0.77\n",
    "        elif genero == 1:\n",
    "            return 1.00\n",
    "    elif edad == 16:\n",
    "        if genero == 2:\n",
    "            return 0.77\n",
    "        elif genero == 1:\n",
    "            return 1.03\n",
    "    elif edad == 17:\n",
    "        if genero == 2:\n",
    "            return 0.77\n",
    "        elif genero == 1:\n",
    "            return 1.04\n",
    "    elif 18 <= edad <= 29:\n",
    "        if genero == 2:\n",
    "            return 0.76\n",
    "        elif genero == 1:\n",
    "            return 1.02\n",
    "    elif 30 <= edad <= 45:\n",
    "        if genero == 2:\n",
    "            return 0.77\n",
    "        elif genero == 1:\n",
    "            return 1.00\n",
    "    elif 46 <= edad <= 60:\n",
    "        if genero == 2:\n",
    "            return 0.76\n",
    "        elif genero == 1:\n",
    "            return 1.00\n",
    "    elif 61 <= edad <= 75:\n",
    "        if genero == 2:\n",
    "            return 0.67\n",
    "        elif genero == 1:\n",
    "            return 0.83\n",
    "    elif edad > 75:\n",
    "        if genero == 2:\n",
    "            return 0.63\n",
    "        elif genero == 1:\n",
    "            return 0.74\n",
    "    else:\n",
    "        return None  # En caso de que no haya una combinación válida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea9446",
   "metadata": {
    "id": "3eea9446"
   },
   "outputs": [],
   "source": [
    "# Aplicamos la funcion al data frame. Creamos una nueva columna llamada 'adulto_equiv' en el DataFrame 'microdata_filtered', donde se calculan y asignan valores equivalentes para adultos\n",
    "# a partir de las edades ('CH06') y géneros ('CH04') de cada fila utilizando una función llamada 'asignar_valor'.\n",
    "\n",
    "merged_microdata['adulto_equiv'] = merged_microdata.apply(lambda row: asignar_valor(row['CH06'], row['CH04']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6c2c4",
   "metadata": {
    "id": "a5c6c2c4"
   },
   "outputs": [],
   "source": [
    "# Limpiamos y Renombramos\n",
    "\n",
    "merged_microdata = merged_microdata.dropna(subset=['adulto_equiv'])\n",
    "\n",
    "result = merged_microdata.groupby(by=['CODUSU','NRO_HOGAR']).agg({'adulto_equiv': 'sum'}).reset_index()\n",
    "result.rename(columns={'adulto_equiv': 'ad_equiv_hogar'}, inplace=True)\n",
    "\n",
    "merged_microdata_FINAL = pd.merge(merged_microdata, result[['CODUSU','NRO_HOGAR', 'ad_equiv_hogar']],\n",
    "                     on=['CODUSU','NRO_HOGAR'],\n",
    "                     how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ed818",
   "metadata": {
    "id": "898ed818"
   },
   "outputs": [],
   "source": [
    "# Definimos ambas bases según los criterios del enunciado, comprobando la condición sobre ITF.\n",
    "# Imprimimos la longitud del DataFrame para obtener las cantidades.\n",
    "\n",
    "# Reemplazar NaN por ceros en ITF_indv e ITF_hogar\n",
    "merged_microdata['ITF_indv'].fillna(0, inplace=True)\n",
    "merged_microdata['ITF_hogar'].fillna(0, inplace=True)\n",
    "\n",
    "respondieron = merged_microdata_FINAL[(merged_microdata_FINAL['ITF_indv'] != 0) | (merged_microdata_FINAL['ITF_hogar'] != 0)]\n",
    "print(len(respondieron))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae571161",
   "metadata": {
    "id": "ae571161"
   },
   "outputs": [],
   "source": [
    "norespondieron = merged_microdata_FINAL[(merged_microdata_FINAL['ITF_indv'] == 0) & (merged_microdata_FINAL['ITF_hogar'] == 0)]\n",
    "print(len(norespondieron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8ef20",
   "metadata": {
    "id": "52c8ef20",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos el valor de la canasta básica y luego\n",
    "# seguimos las instrucciones del enunciado para añadir una columna que indique el ingreso necesario\n",
    "\n",
    "valor_canasta_basica = 57371.05\n",
    "\n",
    "respondieron['ingreso_necesario'] = respondieron['ad_equiv_hogar'] * valor_canasta_basica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d1212",
   "metadata": {
    "id": "0a2d1212"
   },
   "outputs": [],
   "source": [
    "# Creamos una nueva columna llamada 'pobre' en el DataFrame 'respondieron',\n",
    "# donde se asigna un valor de 1 si el valor en la columna 'ITF' es menor que\n",
    "# el valor en la columna 'ingreso_necesario', y 0 en caso contrario, convirtiendo los resultados a enteros.\n",
    "\n",
    "respondieron['pobre'] = ((respondieron['ITF_hogar'] < respondieron['ingreso_necesario']) & (respondieron['ITF_indv'] < respondieron['ingreso_necesario'])).astype(int)\n",
    "\n",
    "# Sumamos todos los 1\n",
    "\n",
    "num_pobres = respondieron['pobre'].sum()\n",
    "\n",
    "print(f'Número de pobres identificados: {num_pobres}')\n",
    "\n",
    "# En %\n",
    "\n",
    "print(num_pobres/len(respondieron))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f1b56",
   "metadata": {
    "id": "1d0f1b56"
   },
   "outputs": [],
   "source": [
    "# Guardamos como csv estas bases por si se desea correr Parte 3 de manera separada a la Parte 1.\n",
    "respondieron.to_csv('respondieron.csv', index=False)\n",
    "norespondieron.to_csv('norespondieron.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26585cfc",
   "metadata": {
    "id": "26585cfc"
   },
   "source": [
    "### Inciso 7\n",
    "Para calcular la tasa de hogares bajo la línea de pobreza utilicen una sola observación por hogar y sumen el ponderador PONDIH que permite expandir la muestra de la EPH al total de la población que representa. ¿Cuál es la tasa de hogares bajo la línea de pobreza para el GBA? ¿Lograron que se asemeje al porcentaje que reporta el INDEC en sus informes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd45a4",
   "metadata": {
    "id": "fdcd45a4"
   },
   "outputs": [],
   "source": [
    "merged_microdata_FINAL['PONDIH_hogar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71621bb1",
   "metadata": {
    "id": "71621bb1"
   },
   "outputs": [],
   "source": [
    "# Agrupar por hogar y utilizar el ponderador PONDIH para calcular la tasa de hogares pobres\n",
    "# Agrupamos los datos por el código del hogar (CODUSU)\n",
    "microdata_repres = respondieron.groupby('CODUSU').first().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee95edee",
   "metadata": {
    "id": "ee95edee"
   },
   "outputs": [],
   "source": [
    "# Ponderacion\n",
    "microdata_repres['ponderacion'] = microdata_repres['PONDIH_indv'] * microdata_repres['pobre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe843b",
   "metadata": {
    "id": "dbbe843b"
   },
   "outputs": [],
   "source": [
    "pobres = microdata_repres['ponderacion'].sum()\n",
    "poblacion = microdata_repres['PONDIH_indv'].sum()\n",
    "porcentaje_pobres = (pobres / poblacion) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e648d",
   "metadata": {
    "id": "901e648d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pobres1 = '{:,}'.format(pobres).replace(',', '.')\n",
    "print(f\"pobres: {pobres1}\")\n",
    "print(f\"tasa {porcentaje_pobres:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36846408",
   "metadata": {
    "id": "36846408"
   },
   "source": [
    "#### La tasa de pobreza nos dio 6 PP mayor que la reportada por el INDEC. Creemos que esto puede ser debido a distintos criterios de limpieza de la base. Aun asi, la diferencia no es tan significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447197d0",
   "metadata": {
    "id": "447197d0"
   },
   "source": [
    "# Parte 2: Construcción de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c271b078",
   "metadata": {
    "executionInfo": {
     "elapsed": 1663,
     "status": "ok",
     "timestamp": 1700520984166,
     "user": {
      "displayName": "Paula Isabel Armas Braithwaite",
      "userId": "03414319077384874698"
     },
     "user_tz": 180
    },
    "id": "c271b078"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from ISLP import load_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952be314",
   "metadata": {
    "id": "952be314"
   },
   "source": [
    "### Inciso 1\n",
    "Escriban una función, llamada evalua metodo, que reciba como argumentos un modelo y los datos de entrenamiento y prueba (X train, y train, X test, y test). La función debe ajustar el modelo con los datos de entrenamiento y calcular las métricas que considere necesarias para esta problemática (de mínima, deben reportar verdaderos positivos, verdaderos negativos, falsos positivos, falsos negativos, AUC, accuracy y precision de cada método). El output de la función debe ser una colección con las métricas evaluadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6195527",
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1700520957057,
     "user": {
      "displayName": "Paula Isabel Armas Braithwaite",
      "userId": "03414319077384874698"
     },
     "user_tz": 180
    },
    "id": "c6195527"
   },
   "outputs": [],
   "source": [
    "def evalua_metodo(model, X_train, y_train, X_test, y_test, plot=True, coef=False):\n",
    "    '''\n",
    "    Evalua un modelo de clasificación proporcionando métricas clave y visualizando la curva ROC.\n",
    "    También puede proveer los coeficientes estimados en el modelo y la proporción de coeficientes iguales a cero.\n",
    "\n",
    "    Input:\n",
    "    - modelo: modelo de clasificación ya instanciado (debe tener los métodos `fit`, `predict` y `predict_proba`).\n",
    "    - X_train, y_train: datos de entrenamiento.\n",
    "    - X_test, y_test: datos de prueba.\n",
    "    - plot (default=True): argumento booleano.\n",
    "    - coef(default=False): argumento booleano.\n",
    "    Output:\n",
    "    - Diccionario con las siguientes métricas:\n",
    "        * matriz_confusion: Matriz de confusión del modelo.\n",
    "        * valor_auc: Área bajo la curva ROC.\n",
    "        * accuracy: Precisión del modelo.\n",
    "        En caso coef=True, también incluye:\n",
    "        * Diccionario de variables y sus coeficientes estimados.\n",
    "        * Proporción de variables con coeficientes estimados iguales a cero.\n",
    "    - Gráfico de la curva ROC si plot=True.\n",
    "    '''\n",
    "    model_to_evaluate = model\n",
    "    # Ajustar el modelo con los datos de entrenamiento\n",
    "    model_fit = model_to_evaluate.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model_fit.predict(X_test)\n",
    "\n",
    "    # Calcular el área bajo la curva ROC y trazar la curva ROC\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "    # Matriz de confusión\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Accuracy Score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Trazar la curva ROC\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', label='Curva ROC (área = %0.2f)' % auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlabel('Tasa de falsos positivos')\n",
    "        plt.ylabel('Tasa de verdaderos positivos')\n",
    "        plt.title('Curva ROC')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "    # ECM\n",
    "    ecm = mean_squared_error(y_test, y_pred) # Deseamos tener esta métrica disponible para la siguiente función.\n",
    "    if coef:\n",
    "        coeficientes = dict(zip(X_train.columns, model_fit.coef_[0])) # Generamos un diccionario donde cada llave es el nombre de una variable y su valor es el coeficiente estimado.\n",
    "        proporcion_variables_cero = sum(value == 0 for value in model_fit.coef_[0]) / len(coeficientes) # Guardamos la proporción de variables con coeficiente estimado igual a cero.\n",
    "\n",
    "    # Retornar las métricas evaluadas\n",
    "    metrics = {\n",
    "        'AUC': auc,\n",
    "        'Confusion Matrix': matriz_confusion,\n",
    "        'Accuracy Score': accuracy,\n",
    "        'ECM': ecm,\n",
    "    }\n",
    "\n",
    "    if coef:\n",
    "        metrics['Coeficientes'] = coeficientes\n",
    "        metrics['Proporción de Variables con Coeficiente Cero'] = proporcion_variables_cero\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b044f",
   "metadata": {
    "id": "f61b044f"
   },
   "source": [
    "### Inciso 2\n",
    "Escriban una función, llamada cross validation, que realice validación cruzada con k iteraciones (k-fold CV), llamando a la función del  inciso anterior en cada una, pero para las k distintas particiones. La función debe recibir como argumentos el modelo, el valor de k y un dataset (es decir, solo X e y). Pueden ayudarse con la función KFold para generar las particiones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8459179",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700520960536,
     "user": {
      "displayName": "Paula Isabel Armas Braithwaite",
      "userId": "03414319077384874698"
     },
     "user_tz": 180
    },
    "id": "c8459179"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfe96f",
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1700520959710,
     "user": {
      "displayName": "Paula Isabel Armas Braithwaite",
      "userId": "03414319077384874698"
     },
     "user_tz": 180
    },
    "id": "07cfe96f"
   },
   "outputs": [],
   "source": [
    "def cross_validation(modelo, k, x, y, std=True, coef=False):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = pd.DataFrame(x)\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = pd.DataFrame(y)\n",
    "\n",
    "    \"\"\"\n",
    "    Realiza validación cruzada k-fold y evalúa un modelo de clasificación en cada partición.\n",
    "\n",
    "    Inputs:\n",
    "    - modelo: modelo de clasificación ya instanciado.\n",
    "    - k: número de particiones para la validación cruzada.\n",
    "    - X: variables independientes del conjunto de datos. Para nuestros fines predictivos, debería ser la muestra de entrenamiento.\n",
    "    - y: variable dependiente (target) del conjunto de datos. Para nuestros fines predictivos, debería ser la muestra de entrenamiento.\n",
    "    - std: argumento booleano.\n",
    "            Si std= True estandarizamos las variables explicativas. Esto es necesario al momento de regularizar por Lasso o Ridge.\n",
    "    - coef: argumento booleano.\n",
    "    Outputs:\n",
    "    - Un DataFrame con k filas, una para cada iteración de la validación cruzada. Tiene las siguientes columnas:\n",
    "        - partición: número de partición\n",
    "        - el error cuadrático medio (ECM)\n",
    "        - Si Coef=True, reportamos la proporción de variables iguales a cero.\n",
    "        Esto nos sirve para analizar el resultado de regularizar vía Lasso.\n",
    "\n",
    "    \"\"\"\n",
    "    sc = StandardScaler()\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=2023)\n",
    "    output = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(x)):\n",
    "        x_train, x_valid = x.iloc[list(train_index)], x.iloc[list(valid_index)]\n",
    "        y_train, y_valid = y.iloc[list(train_index)], y.iloc[list(valid_index)]\n",
    "\n",
    "        if std:\n",
    "            x_train = pd.DataFrame(sc.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "            x_valid = pd.DataFrame(sc.transform(x_valid), index=x_valid.index, columns=x_valid.columns)\n",
    "\n",
    "        # Llamar a evalua_metodo para calcular las métricas\n",
    "        metrics = evalua_metodo(modelo, x_train, y_train, x_valid, y_valid, plot=False, coef=coef)\n",
    "\n",
    "        # Extraer las métricas calculadas en evalua_metodo\n",
    "        matriz_confusion = metrics['Confusion Matrix']\n",
    "        valor_auc = metrics['AUC']\n",
    "        accuracy = metrics['Accuracy Score']\n",
    "        ecm = metrics['ECM']\n",
    "        proporcion_variables_cero = None\n",
    "\n",
    "        if coef:\n",
    "            proporcion_variables_cero = metrics['Proporción de Variables con Coeficiente Cero']\n",
    "\n",
    "        output.append((i + 1, ecm, valor_auc, accuracy, matriz_confusion, proporcion_variables_cero))\n",
    "\n",
    "    output_df = pd.DataFrame(output, columns=[\"Particion\", \"MSE\", \"valor_auc\", \"accuracy\", \"matriz_confusion\", \"proporcion_variables_cero\"])\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efd06e",
   "metadata": {
    "id": "24efd06e"
   },
   "source": [
    "### Inciso 3\n",
    "Escriban una función, llamada evalua config que reciba una lista de configuraciones de hiperparámetros (los distintos valores a probar como hiper-parámetros podrian codificarse en diccionarios de Python)y utilizando la función cross validation obtenga el error cuadrado promedio para cada configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20798665",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1700520962804,
     "user": {
      "displayName": "Paula Isabel Armas Braithwaite",
      "userId": "03414319077384874698"
     },
     "user_tz": 180
    },
    "id": "20798665"
   },
   "outputs": [],
   "source": [
    "def evalua_config(model_types, hiperparam, X_T, y_T,rep=10, declar=True):\n",
    "    \"\"\"\n",
    "    Encuentra el valor óptimo de lambda para Ridge, Lasso o ambos si el modelo es Logístico y el número óptimo de vecinos si el modelo es K-Vecinos Cercanos.\n",
    "    Inputs:\n",
    "    - model_types: Lista de tipos de modelo ('ridge', 'lasso', ambos o k-vecinos cercanos). K-vecinos cercanos se debe analizar de manera separada a \"ridge\" y/o \"lasso\", o no se ejecuta.\n",
    "    - hiperparam: Lista de valores de lambda o de número de vecinos cercanos para evaluar. Los valores de vecinos cercanos deben ser todos números enteros.\n",
    "    - X_T: Variables explicativas. Debería ser la muestra de entrenamiento.\n",
    "    - y_T: Variable objetivo (etiquetas binarias 0 y 1). Debería ser la muestra de entrenamiento.\n",
    "    -rep: número de particiones para la validación cruzada.\n",
    "    - declar: argumento booleano que imprime la configuración óptima if True. No lo hace d.o.m.\n",
    "    Outputs:\n",
    "    - DataFrame que contiene: el método de regularización, los valores de los hiperparámetros y los errores cuadráticos medios para los modelos seleccionados.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if not all(model_type in ['ridge', 'lasso','k vecinos'] for model_type in model_types):\n",
    "        raise ValueError(\"Los elementos en 'model_types' deben ser 'ridge', 'lasso', o k vecinos.\")\n",
    "    if ('ridge' in model_types or 'lasso' in model_types) and 'k vecinos' in model_types:\n",
    "        raise ValueError(\"Error: 'ridge' o 'lasso' no pueden estar en la lista junto con 'k vecinos'.\")\n",
    "    resultados_all = []\n",
    "    model_types_log= [config for config in model_types if config != \"k vecinos\"]\n",
    "    k_neighbors=[config for config in model_types if config == \"k vecinos\"]\n",
    "    for model_type in model_types_log:\n",
    "        if model_type == 'ridge':\n",
    "            modelo = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "        else:\n",
    "            modelo = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "        for alpha in hiperparam:\n",
    "            modelo.set_params(C=1/alpha)\n",
    "            # Realizar validación cruzada utilizando cross_validation\n",
    "            resultados = cross_validation(modelo, k=rep, x=X_T, y=y_T, std=True)\n",
    "            # Calcular el Error Cuadrático Medio (ECM) promedio\n",
    "            ecm_promedio = np.mean(resultados['MSE'])\n",
    "            resultados_all.append((model_type, alpha, ecm_promedio))\n",
    "    if k_neighbors:\n",
    "      for model_type in k_neighbors:\n",
    "          if any(not isinstance(param, int) for param in hiperparam):\n",
    "            raise ValueError(\"Los hiperparámetros deben ser números enteros para 'k vecinos'.\")\n",
    "          for n in hiperparam:\n",
    "              modelo = KNeighborsClassifier(n_neighbors=n)\n",
    "          # Realizar validación cruzada utilizando cross_validation\n",
    "              resultados = cross_validation(modelo, k=rep, x=X_T, y=y_T, std=True)\n",
    "            # Calcular el Error Cuadrático Medio (ECM) promedio\n",
    "              ecm_promedio = np.mean(resultados['MSE'])\n",
    "              resultados_all.append((model_type, n, ecm_promedio))\n",
    "    #(n_neighbors=5)\n",
    "    # Crear un DataFrame a partir de la lista de tuplas\n",
    "    resultados_df = pd.DataFrame(resultados_all, columns=[\"Model Type\", \"Hiperparam\", \"ECM\"])\n",
    "    #min_ecm = resultados_df['ECM'].min()\n",
    "    #resultados_df['config. óptima'] = resultados_df['ECM'] == min_ecm\n",
    "    optimal_configuration = resultados_df.loc[resultados_df['ECM'].idxmin()]\n",
    "    optimal_lambda = optimal_configuration['Hiperparam']\n",
    "    optimal_model_type = optimal_configuration['Model Type']\n",
    "    if declar:\n",
    "        print(f\"La configuración óptima es: Hiperparámetro = {optimal_lambda}, Model Type = {optimal_model_type}\")\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc00c5c",
   "metadata": {
    "id": "4dc00c5c"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e3adb6",
   "metadata": {
    "id": "55e3adb6"
   },
   "source": [
    "### Inciso 4\n",
    "Escriban una función llamada \"evalua multiples metodos\" que les permita implementar los siguiente métodos con los hiperparámetros que ustedes elijan. Para la regresión logística, asegúrense de que esta función utilice su función. Evalua config para optimizar el λ de la regularización. Finalmente, el output de la función debe ser una tabla donde las columnas sean las métricas que hayan evaluado (las que hayan incluido en la función evalua metodo) y las filas sean los modelos (con su configuración de hiperparámetros asociada) que hayan corrido. Asegúrense de que la tabla incluya una columna con nombre del modelo y el valor de los hiperparámetros/configuración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GlKuWYUB92ks",
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1700524558140,
     "user": {
      "displayName": "Paula Isabel Armas Braithwaite",
      "userId": "03414319077384874698"
     },
     "user_tz": 180
    },
    "id": "GlKuWYUB92ks"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def evalua_multiples_metodos(X_train, y_train, X_test, y_test, metodos):\n",
    "    \"\"\"\n",
    "    Evalúa varios métodos de clasificación con hiperparámetros personalizados y regresión logística con optimización de lambda.\n",
    "\n",
    "    Inputs:\n",
    "    - X_train: variables explicativas, datos de la muestra de entrenamiento\n",
    "    - X_test: variables explicativas, datos de la muestra de prueba\n",
    "    - Y_train: variable objetivo binaria, datos de la muestra de entrenamiento\n",
    "    - Y_test: variable objetivo binaria, datos de la muestra de prueba\n",
    "    - metodos: Lista de diccionarios que especifican los modelos (Regresión Logística, KNN y ADL) y sus hiperparámetros.\n",
    "    Outputs:\n",
    "    - DataFrame que contiene las métricas evaluadas para cada modelo, el nombre del modelo, los hiperparámetros utilizados, el método de regularización para el modelo logit y el número del hiperparámetro óptimo para el modelo logit.\n",
    "    Nota: estandarizamos las variables explicativas en dos instancias. Primero, evalua_config estandariza las variables explicativas dentro de cada submuestra como\n",
    "    parte de la configuración de su función interna cross_validation. Luego, para comparar la performance de los modelos, los corremos utilizando las variables estandarizadas dentro\n",
    "    de la muestra de entrenamiento y de prueba.\n",
    "    \"\"\"\n",
    "    resultados = []  # Resultados como una lista de diccionarios\n",
    "\n",
    "    for metodo in metodos:\n",
    "        nombre_modelo = metodo['nombre']\n",
    "        hiperparametros = metodo['hiperparametros']\n",
    "        resultados_modelo = {}  # Inicializar resultados_modelo\n",
    "        sc = StandardScaler()\n",
    "        X_train_std = pd.DataFrame(sc.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "        X_test_std = pd.DataFrame(sc.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "        if nombre_modelo == 'Regresión Logística':\n",
    "            # Optimizar lambda (α) para la regularización de la Regresión Logística\n",
    "            lambdas = hiperparametros.get('lambdas', [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]) ## Default de lambdas a evaluar.\n",
    "            resultados_log = evalua_config(['ridge', 'lasso'], lambdas, X_train, y_train, declar=False)\n",
    "            mejor_lambda = resultados_log.loc[resultados_log['ECM'].idxmin()]['Hiperparam']\n",
    "            mejor_metodo = resultados_log.loc[resultados_log['ECM'].idxmin()]['Model Type']\n",
    "            if mejor_metodo == \"ridge\":\n",
    "                modelo = LogisticRegression(penalty='l2', C=1/mejor_lambda, solver='liblinear')\n",
    "            else:\n",
    "                modelo = LogisticRegression(penalty='l1', C=1/mejor_lambda, solver='liblinear')\n",
    "\n",
    "            resultados_modelo = evalua_metodo(modelo, X_train_std, y_train, X_test_std, y_test, plot=False)\n",
    "        elif nombre_modelo == 'Análisis de Discriminante Lineal':\n",
    "            # Crear el modelo de Análisis de Discriminante Lineal con los hiperparámetros personalizados\n",
    "            modelo = LinearDiscriminantAnalysis(**hiperparametros)\n",
    "            # Evaluar el modelo\n",
    "            resultados_modelo = evalua_metodo(modelo, X_train_std, y_train, X_test_std, y_test, plot=False)\n",
    "        elif nombre_modelo == 'KNN':\n",
    "            # Optimizar el número de vecinos cercanos\n",
    "            n_vecinos = hiperparametros.get('n_neighbors',[3,5,10]) ## Default de # de vecinos a evaluar.\n",
    "            resultados_vecinos = evalua_config(['k vecinos'], n_vecinos, X_train, y_train, declar=False)\n",
    "            mejor_k = resultados_vecinos.loc[resultados_vecinos['ECM'].idxmin()]['Hiperparam']\n",
    "            # Crear el modelo K-Nearest Neighbors (KNN) con el hiperparámetro óptimo\n",
    "            modelo = KNeighborsClassifier(n_neighbors=mejor_k)\n",
    "            # Evaluar el modelo\n",
    "            resultados_modelo = evalua_metodo(modelo, X_train_std, y_train, X_test_std, y_test, plot=False)\n",
    "        elif nombre_modelo in ['Decision Tree', 'Bagging', 'Random Forest', 'Ada Boost']:\n",
    "            # Crear una instancia base del modelo para obtener los hiperparámetros óptimos\n",
    "            base_modelo = None\n",
    "            if nombre_modelo == 'Decision Tree':\n",
    "                base_modelo = DecisionTreeClassifier(random_state=1)\n",
    "            elif nombre_modelo == 'Bagging':\n",
    "                base_modelo = BaggingClassifier(random_state=1)\n",
    "            elif nombre_modelo == 'Random Forest':\n",
    "                base_modelo = RandomForestClassifier(random_state=1)\n",
    "            elif nombre_modelo == 'Ada Boost':\n",
    "                base_modelo = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "            params_grid = hiperparametros\n",
    "            cv = KFold(n_splits=5, random_state=41, shuffle=True)\n",
    "            grid = GridSearchCV(estimator=base_modelo, param_grid=params_grid, cv=cv, verbose=0)\n",
    "            grid.fit(X_train_std, y_train)\n",
    "            params = grid.best_params_\n",
    "            \n",
    "            # Evaluar el modelo con los hiperparámetros óptimos\n",
    "            modelo = base_modelo.__class__(**params)\n",
    "            resultados_modelo = evalua_metodo(modelo, X_train_std, y_train, X_test_std, y_test, plot=False)\n",
    "            hiperparam_optimos = {k: v for k, v in params.items()}  # Obtener todos los hiperparámetros\n",
    "\n",
    "        resultados_modelo['Modelo'] = nombre_modelo\n",
    "        resultados_modelo['Hiperparámetros'] = str(hiperparametros)\n",
    "\n",
    "        if nombre_modelo == 'Regresión Logística':\n",
    "            resultados_modelo['Método de Regularización'] = mejor_metodo\n",
    "            resultados_modelo['Hiperparámetro Óptimo'] = mejor_lambda\n",
    "        elif nombre_modelo == 'KNN':\n",
    "            resultados_modelo['Método de Regularización'] = None\n",
    "            resultados_modelo['Hiperparámetro Óptimo'] = mejor_k\n",
    "        elif nombre_modelo in ['Decision Tree', 'Bagging', 'Random Forest', 'Ada Boost']:\n",
    "            resultados_modelo['Método de Regularización'] = None\n",
    "            resultados_modelo['Hiperparámetro Óptimo'] = hiperparam_optimos\n",
    "        else:\n",
    "            resultados_modelo['Método de Regularización'] = None\n",
    "            resultados_modelo['Hiperparámetro Óptimo'] = None\n",
    "\n",
    "        resultados.append(resultados_modelo)\n",
    "\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "    return resultados_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db386e",
   "metadata": {
    "id": "e2db386e"
   },
   "source": [
    "# Parte 3: Análisis de la base de hogares y cálculo de pobreza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986c02a",
   "metadata": {
    "id": "2986c02a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from ISLP import load_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4981b",
   "metadata": {
    "id": "05c4981b"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb302823",
   "metadata": {
    "id": "eb302823"
   },
   "source": [
    "### Inciso 1\n",
    "Eliminen de ambas bases (respondieron, norespondieron) todas las variables relacionadas a ingresos (en el archivo Diseño de bases y estructura ver las categorías: ingresos de la ocupación principal de los asalariados, ingresos de la ocupación principal, ingresos de otras ocupaciones, ingreso total individual, ingresos no laborales, ingreso total familiar, ingreso per cápita familiar). Eliminen también las columnas adulto_equiv, ad_equiv_hogar e ingreso_necesario. Establezcan a la variable pobre como su variable dependiente (vector y). El resto de las variables serán las variables independientes (matriz X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe00d55",
   "metadata": {
    "id": "8fe00d55"
   },
   "outputs": [],
   "source": [
    "# Eliminar columnas específicas\n",
    "respondieron = respondieron.drop(columns=['CODUSU'])\n",
    "\n",
    "# Eliminar un rango de columnas: ingresos de la ocupación principal de los asalariados\n",
    "respondieron = respondieron.drop(columns=[col for col in respondieron.columns if col.startswith('PP08')])\n",
    "\n",
    "# Eliminar un rango de columnas: Ingresos de la ocupación principal de los trabajadores independientes\n",
    "respondieron = respondieron.drop(columns=[col for col in respondieron.columns if col.startswith('PP06')])\n",
    "\n",
    "# Ingresos de la ocupación principal\n",
    "start = respondieron.columns.get_loc('P21')\n",
    "end = respondieron.columns.get_loc('PONDIH_indv')\n",
    "\n",
    "columns_to_drop = respondieron.columns[start:end+1]\n",
    "respondieron = respondieron.drop(columns=columns_to_drop)\n",
    "\n",
    "# Ingresos de la ocupación principal\n",
    "start = respondieron.columns.get_loc('ITF_hogar')\n",
    "end = respondieron.columns.get_loc('PONDIH_hogar')\n",
    "\n",
    "columns_to_drop = respondieron.columns[start:end+1]\n",
    "respondieron = respondieron.drop(columns=columns_to_drop)\n",
    "\n",
    "# Ingresos de la ocupación principal\n",
    "start = respondieron.columns.get_loc('adulto_equiv')\n",
    "end = respondieron.columns.get_loc('ingreso_necesario')\n",
    "\n",
    "columns_to_drop = respondieron.columns[start:end+1]\n",
    "respondieron = respondieron.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c210db7",
   "metadata": {
    "id": "0c210db7"
   },
   "outputs": [],
   "source": [
    "# Eliminar columnas específicas\n",
    "#norespondieron = norespondieron.drop(columns=['CODUSU'])\n",
    "\n",
    "# Las columnas ingresos de la ocupación principal de los asalariados e Ingresos de la ocupación principal de\n",
    "# los trabajadores independientes fueron eliminadas previamente en la Parte 1 por su alto contenido de NAs\n",
    "\n",
    "# Ingresos de la ocupación principal\n",
    "start = norespondieron.columns.get_loc('P21')\n",
    "end = norespondieron.columns.get_loc('PONDIH_indv')\n",
    "\n",
    "columns_to_drop = norespondieron.columns[start:end+1]\n",
    "norespondieron = norespondieron.drop(columns=columns_to_drop)\n",
    "\n",
    "# Ingresos de la ocupación principal\n",
    "start = norespondieron.columns.get_loc('ITF_hogar')\n",
    "end = norespondieron.columns.get_loc('PONDIH_hogar')\n",
    "\n",
    "columns_to_drop = norespondieron.columns[start:end+1]\n",
    "norespondieron = norespondieron.drop(columns=columns_to_drop)\n",
    "\n",
    "# Ingresos de la ocupación principal\n",
    "start = norespondieron.columns.get_loc('adulto_equiv')\n",
    "end = norespondieron.columns.get_loc('ad_equiv_hogar')\n",
    "\n",
    "columns_to_drop = norespondieron.columns[start:end+1]\n",
    "norespondieron = norespondieron.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8a116",
   "metadata": {
    "id": "46e8a116"
   },
   "outputs": [],
   "source": [
    "# Definimos la matriz de Xs\n",
    "X = respondieron.drop(['pobre'], axis=1)\n",
    "y = respondieron.pobre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd4d67",
   "metadata": {
    "id": "d9fd4d67"
   },
   "source": [
    "### Inciso 2\n",
    "Corran la función evalua multiples metodos con la base respondieron. Asegúrense de estar utilizando su función de evalua_config para optimizar algunos hiperparámetros (de mínima, el K en el modelo KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b80265",
   "metadata": {
    "id": "89b80265"
   },
   "outputs": [],
   "source": [
    "# Primero, definimos los hiperparámetros para cada método\n",
    "hiperparametros_rl = {\n",
    "    'lambdas': [1, 10, 100],\n",
    "}\n",
    "\n",
    "hiperparametros_lda = {\n",
    "    'solver': 'lsqr',\n",
    "}\n",
    "\n",
    "hiperparametros_knn = {\n",
    "    'n_neighbors': [3, 5, 10],\n",
    "}\n",
    "\n",
    "hiperparametros_dt = {\n",
    "    'max_depth': [None, 5, 10, 15, 20, 30, 40]\n",
    "}\n",
    "\n",
    "hiperparametros_bagging = {\n",
    "    'n_estimators': [200, 250, 300, 350, 400, 500],\n",
    "    'max_samples': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "hiperparametros_rf = {\n",
    "    'n_estimators': [200, 250, 300, 350, 400, 500],\n",
    "    'max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "hiperparametros_ada_boost = {\n",
    "    'n_estimators': [200, 250, 300, 350, 400, 500],\n",
    "    'learning_rate': [0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Lista de métodos y sus hiperparámetros\n",
    "metodos = [\n",
    "    {\n",
    "        'nombre': 'Regresión Logística',\n",
    "        'hiperparametros': hiperparametros_rl,\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Análisis de Discriminante Lineal',\n",
    "        'hiperparametros': hiperparametros_lda,\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'KNN',\n",
    "        'hiperparametros': hiperparametros_knn,\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Decision Tree',\n",
    "        'hiperparametros': hiperparametros_dt,\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Bagging',\n",
    "        'hiperparametros': hiperparametros_bagging,\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Random Forest',\n",
    "        'hiperparametros': hiperparametros_rf,\n",
    "    },\n",
    "    {\n",
    "        'nombre': 'Ada Boost',\n",
    "        'hiperparametros': hiperparametros_ada_boost,\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b0111",
   "metadata": {
    "id": "b35b0111"
   },
   "outputs": [],
   "source": [
    "### Segundo, definimos la muestra de entrenamiento y de prueba.\n",
    "# Para probar evalúa_metodo vamos a separar la muestra en train y test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "# Ahora llamamos a la función\n",
    "resultados_df=evalua_multiples_metodos(X_train,y_train,X_test,y_test, metodos)\n",
    "# Ver los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea515f",
   "metadata": {
    "id": "bcea515f",
    "outputId": "ba54c1f8-d747-4746-a293-852f38bcadb3"
   },
   "outputs": [],
   "source": [
    "resultados_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72087962",
   "metadata": {
    "id": "72087962"
   },
   "source": [
    "### Inciso 3\n",
    "\n",
    "¿Cuál de todos los métodos evaluados predice mejor? ¿Con qué hiperparámetros? Justifiquen mencionando las métricas que conocen.\n",
    "\n",
    "Evaluando las métricas proporcionadas para cada modelo:\n",
    "\n",
    "El modelo de Bagging muestra el mejor desempeño en general, basado en las métricas proporcionadas. Tiene un área bajo la curva (AUC) más alto, alcanzando 0.887426, lo que sugiere una excelente capacidad para distinguir entre las clases.\n",
    "\n",
    "Su precisión general, medida por el Accuracy Score, es alta (0.889597), lo que indica un buen rendimiento en la clasificación correcta de las muestras. Además, el ECM es el mas bajo, registrando 0.110403, lo que refleja precisión en las predicciones.\n",
    "\n",
    "Al analizar la Confusion Matrix, observamos un bajo número de falsos positivos y falsos negativos, lo que confirma la capacidad del modelo para predecir con precisión ambas clases.\n",
    "\n",
    "En contraste, otros modelos como Análisis de Discriminante Lineal, KNN, y Ada Boost tienen métricas ligeramente más bajas en comparación con el modelo de Bagging en términos de AUC y precisión general.\n",
    "\n",
    "Basado en estas métricas, el modelo de Bagging, con hiperparámetros de max_samples=1.0 y n_estimators=400, parece ser el más sólido y equilibrado en su rendimiento predictivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f8a70",
   "metadata": {},
   "source": [
    "### Inciso 4\n",
    "\n",
    "¿Lograron mejorar sus predicción respecto al TP3?\n",
    "\n",
    "Las predicciones ahora tienen una precisión notablemente mayor. Hubo un aumento de más del 10 PP en la métrica de precisión, y se observó una mejora en casi todas las demás métricas con la utilización del modelo Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e60c7",
   "metadata": {
    "id": "1f5e60c7"
   },
   "source": [
    "### Inciso 5\n",
    "Con el método que seleccionaron, predigan qué personas son pobres dentro de la base norespondieron. ¿Qué proporción de los hogares son pobres en esa submuestra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0fb1db",
   "metadata": {
    "id": "ec0fb1db",
    "outputId": "ea7eabf9-e17b-40ec-b535-d1aef5db607c"
   },
   "outputs": [],
   "source": [
    "# Crear una instancia del modelo Bagging\n",
    "modelo_lda = BaggingClassifier(max_samples=1.0, n_estimators=400)\n",
    "\n",
    "# Ajustar el modelo LDA con los datos de entrenamiento\n",
    "modelo_lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45dd2a",
   "metadata": {
    "id": "de45dd2a",
    "outputId": "dfe6232e-b94c-4603-82dc-4995bd28fe6d"
   },
   "outputs": [],
   "source": [
    "# Supongamos que tienes la muestra \"norespondieron\" en un DataFrame llamado \"norespondieron_df\"\n",
    "\n",
    "# Realiza predicciones en la submuestra \"norespondieron\"\n",
    "norespondieron_sin_codusu = norespondieron.drop(columns=['CODUSU']).copy()\n",
    "\n",
    "predicciones = modelo_lda.predict(norespondieron_sin_codusu)\n",
    "\n",
    "# Calcula la proporción de hogares pobres en la submuestra\n",
    "proporcion_pobres = sum(predicciones) / len(predicciones)\n",
    "\n",
    "print(\"Proporción de hogares pobres en la submuestra 'norespondieron':\", proporcion_pobres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b718fa",
   "metadata": {
    "id": "49b718fa"
   },
   "outputs": [],
   "source": [
    "norespondieron['pobre'] = predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692637cd",
   "metadata": {
    "id": "692637cd",
    "outputId": "ca308591-525d-4b80-9cb1-67e52bc74079"
   },
   "outputs": [],
   "source": [
    "merged_data1 = merged_microdata_FINAL.merge(norespondieron, on='CODUSU', how='inner')\n",
    "# Agrupar por hogar y utilizar el ponderador PONDIH para calcular la tasa de hogares pobres\n",
    "# Agrupamos los datos por el código del hogar (CODUSU)\n",
    "microdata_repres = merged_data1.groupby('CODUSU').first().reset_index()\n",
    "# Ponderacion\n",
    "microdata_repres['ponderacion'] = microdata_repres['PONDIH_indv'] * microdata_repres['pobre']\n",
    "pobres = microdata_repres['ponderacion'].sum()\n",
    "poblacion = microdata_repres['PONDIH_indv'].sum()\n",
    "porcentaje_pobres = (pobres / poblacion) * 100\n",
    "pobres1 = '{:,}'.format(pobres).replace(',', '.')\n",
    "print(f\"pobres: {pobres1}\")\n",
    "print(f\"tasa {porcentaje_pobres:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "63417974",
    "e2db386e",
    "f2f5b885",
    "ddffd4f2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
